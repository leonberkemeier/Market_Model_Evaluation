{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Linear Models for Financial Prediction\n",
    "\n",
    "This notebook trains and evaluates linear regression models for predicting stock returns.\n",
    "\n",
    "## Objectives\n",
    "1. Load prepared training data\n",
    "2. Train multiple linear models (Linear Regression, Ridge, Lasso, ElasticNet)\n",
    "3. Evaluate model performance\n",
    "4. Compare models and select the best one\n",
    "5. Analyze feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /home/archy/Desktop/Server/FinancialData/model_regime_comparison/data/prepared\n",
      "Model directory: /home/archy/Desktop/Server/FinancialData/model_regime_comparison/models\n",
      "Target variable: forward_return_5d\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "DATA_DIR = Path('/home/archy/Desktop/Server/FinancialData/model_regime_comparison/data/prepared')\n",
    "MODEL_DIR = Path('/home/archy/Desktop/Server/FinancialData/model_regime_comparison/models')\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Target variable to predict\n",
    "TARGET = 'forward_return_5d'  # Can also use 'forward_return_30d'\n",
    "\n",
    "# Columns to exclude from features\n",
    "EXCLUDE_COLS = ['ticker', 'date', 'close', 'forward_return_5d', 'forward_return_30d']\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Model directory: {MODEL_DIR}\")\n",
    "print(f\"Target variable: {TARGET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shapes:\n",
      "  Training: (11580, 41)\n",
      "  Validation: (1240, 41)\n",
      "  Test: (980, 41)\n",
      "\n",
      "Columns: 41\n",
      "Date range (train): 2019-05-28 00:00:00 to 2023-12-29 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "train_df = pd.read_parquet(DATA_DIR / 'finance_train.parquet')\n",
    "val_df = pd.read_parquet(DATA_DIR / 'finance_val.parquet')\n",
    "test_df = pd.read_parquet(DATA_DIR / 'finance_test.parquet')\n",
    "\n",
    "print(\"Dataset shapes:\")\n",
    "print(f\"  Training: {train_df.shape}\")\n",
    "print(f\"  Validation: {val_df.shape}\")\n",
    "print(f\"  Test: {test_df.shape}\")\n",
    "\n",
    "print(f\"\\nColumns: {len(train_df.columns)}\")\n",
    "print(f\"Date range (train): {train_df['date'].min()} to {train_df['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 36\n",
      "\n",
      "Feature columns:\n",
      "   1. momentum_5d\n",
      "   2. momentum_20d\n",
      "   3. momentum_60d\n",
      "   4. volatility_20d\n",
      "   5. volatility_60d\n",
      "   6. rsi_14\n",
      "   7. macd_line\n",
      "   8. macd_signal\n",
      "   9. macd_histogram\n",
      "  10. bb_upper\n",
      "  11. bb_middle\n",
      "  12. bb_lower\n",
      "  13. bb_percent_b\n",
      "  14. price_to_sma_20\n",
      "  15. price_to_sma_50\n",
      "  16. price_to_sma_200\n",
      "  17. volume_trend\n",
      "  18. has_data\n",
      "  19. sector\n",
      "  20. industry\n",
      "  21. country\n",
      "  22. exchange\n",
      "  23. has_filings\n",
      "  24. avg_filing_size\n",
      "  25. filing_frequency\n",
      "  26. pe_ratio\n",
      "  27. debt_equity_ratio\n",
      "  28. current_ratio\n",
      "  29. roe\n",
      "  30. roa\n",
      "  31. asset_turnover\n",
      "  32. profit_margin\n",
      "  33. free_cash_flow_yield\n",
      "  34. revenue_growth\n",
      "  35. earnings_growth\n",
      "  36. sector_rotation\n",
      "\n",
      "Feature matrix shape: (11580, 36)\n",
      "Target shape: (11580,)\n"
     ]
    }
   ],
   "source": [
    "# Get feature columns\n",
    "feature_cols = [col for col in train_df.columns if col not in EXCLUDE_COLS]\n",
    "\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(f\"\\nFeature columns:\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# Separate features and target\n",
    "X_train = train_df[feature_cols].copy()\n",
    "y_train = train_df[TARGET].copy()\n",
    "\n",
    "X_val = val_df[feature_cols].copy()\n",
    "y_val = val_df[TARGET].copy()\n",
    "\n",
    "X_test = test_df[feature_cols].copy()\n",
    "y_test = test_df[TARGET].copy()\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X_train.shape}\")\n",
    "print(f\"Target shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "  X_train: 145908\n",
      "  y_train: 0\n",
      "  X_val: 15624\n",
      "  y_val: 0\n",
      "\n",
      "Dropping rows with missing values...\n",
      "\n",
      "Final shapes:\n",
      "  Train: (0, 36), (0,)\n",
      "  Val: (0, 36), (0,)\n"
     ]
    }
   ],
   "source": [
    "# Check for any remaining missing values\n",
    "print(\"Missing values:\")\n",
    "print(f\"  X_train: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"  y_train: {y_train.isnull().sum()}\")\n",
    "print(f\"  X_val: {X_val.isnull().sum().sum()}\")\n",
    "print(f\"  y_val: {y_val.isnull().sum()}\")\n",
    "\n",
    "# Drop any rows with missing values if found\n",
    "if X_train.isnull().any().any() or y_train.isnull().any():\n",
    "    print(\"\\nDropping rows with missing values...\")\n",
    "    train_mask = ~(X_train.isnull().any(axis=1) | y_train.isnull())\n",
    "    X_train = X_train[train_mask]\n",
    "    y_train = y_train[train_mask]\n",
    "    \n",
    "if X_val.isnull().any().any() or y_val.isnull().any():\n",
    "    val_mask = ~(X_val.isnull().any(axis=1) | y_val.isnull())\n",
    "    X_val = X_val[val_mask]\n",
    "    y_val = y_val[val_mask]\n",
    "    \n",
    "print(f\"\\nFinal shapes:\")\n",
    "print(f\"  Train: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"  Val: {X_val.shape}, {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 36)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Standardize features\u001b[39;00m\n\u001b[32m      2\u001b[39m scaler = StandardScaler()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m X_train_scaled = \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m X_val_scaled = scaler.transform(X_val)\n\u001b[32m      5\u001b[39m X_test_scaled = scaler.transform(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Server/FinancialData/model_regime_comparison/venv/lib/python3.14/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Server/FinancialData/model_regime_comparison/venv/lib/python3.14/site-packages/sklearn/base.py:907\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    892\u001b[39m         warnings.warn(\n\u001b[32m    893\u001b[39m             (\n\u001b[32m    894\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    902\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    903\u001b[39m         )\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    906\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m907\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n\u001b[32m    908\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    909\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    910\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Server/FinancialData/model_regime_comparison/venv/lib/python3.14/site-packages/sklearn/preprocessing/_data.py:924\u001b[39m, in \u001b[36mStandardScaler.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    923\u001b[39m \u001b[38;5;28mself\u001b[39m._reset()\n\u001b[32m--> \u001b[39m\u001b[32m924\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Server/FinancialData/model_regime_comparison/venv/lib/python3.14/site-packages/sklearn/base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Server/FinancialData/model_regime_comparison/venv/lib/python3.14/site-packages/sklearn/preprocessing/_data.py:961\u001b[39m, in \u001b[36mStandardScaler.partial_fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    959\u001b[39m xp, _, X_device = get_namespace_and_device(X)\n\u001b[32m    960\u001b[39m first_call = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mn_samples_seen_\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_device\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    969\u001b[39m n_features = X.shape[\u001b[32m1\u001b[39m]\n\u001b[32m    971\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Server/FinancialData/model_regime_comparison/venv/lib/python3.14/site-packages/sklearn/utils/validation.py:2902\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2900\u001b[39m         out = X, y\n\u001b[32m   2901\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2902\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2903\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2904\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Server/FinancialData/model_regime_comparison/venv/lib/python3.14/site-packages/sklearn/utils/validation.py:1097\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1095\u001b[39m     n_samples = _num_samples(array)\n\u001b[32m   1096\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_samples < ensure_min_samples:\n\u001b[32m-> \u001b[39m\u001b[32m1097\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1098\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) while a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1099\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1100\u001b[39m             % (n_samples, array.shape, ensure_min_samples, context)\n\u001b[32m   1101\u001b[39m         )\n\u001b[32m   1103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array.ndim == \u001b[32m2\u001b[39m:\n\u001b[32m   1104\u001b[39m     n_features = array.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Found array with 0 sample(s) (shape=(0, 36)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"âœ“ Features scaled\")\n",
    "print(f\"\\nScaled feature statistics (train):\")\n",
    "print(f\"  Mean: {X_train_scaled.mean(axis=0).mean():.6f}\")\n",
    "print(f\"  Std: {X_train_scaled.std(axis=0).mean():.6f}\")\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, MODEL_DIR / 'scaler.pkl')\n",
    "print(f\"\\nâœ“ Scaler saved to {MODEL_DIR / 'scaler.pkl'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to train\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge (Î±=1.0)': Ridge(alpha=1.0, random_state=42),\n",
    "    'Ridge (Î±=10.0)': Ridge(alpha=10.0, random_state=42),\n",
    "    'Ridge (Î±=100.0)': Ridge(alpha=100.0, random_state=42),\n",
    "    'Lasso (Î±=0.001)': Lasso(alpha=0.001, random_state=42, max_iter=10000),\n",
    "    'Lasso (Î±=0.01)': Lasso(alpha=0.01, random_state=42, max_iter=10000),\n",
    "    'ElasticNet (Î±=0.01)': ElasticNet(alpha=0.01, l1_ratio=0.5, random_state=42, max_iter=10000)\n",
    "}\n",
    "\n",
    "print(f\"Training {len(models)} models...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_val_pred = model.predict(X_val_scaled)\n",
    "    \n",
    "    # Evaluate\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    \n",
    "    val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "    val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "    val_r2 = r2_score(y_val, y_val_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Train MSE': train_mse,\n",
    "        'Train RMSE': np.sqrt(train_mse),\n",
    "        'Train MAE': train_mae,\n",
    "        'Train RÂ²': train_r2,\n",
    "        'Val MSE': val_mse,\n",
    "        'Val RMSE': np.sqrt(val_mse),\n",
    "        'Val MAE': val_mae,\n",
    "        'Val RÂ²': val_r2,\n",
    "        'model_object': model\n",
    "    })\n",
    "    \n",
    "    print(f\"  Train RMSE: {np.sqrt(train_mse):.6f}, Val RMSE: {np.sqrt(val_mse):.6f}\")\n",
    "    print(f\"  Train RÂ²: {train_r2:.6f}, Val RÂ²: {val_r2:.6f}\\n\")\n",
    "\n",
    "print(\"âœ“ All models trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "results_display = results_df.drop('model_object', axis=1)\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(\"=\" * 100)\n",
    "print(results_display.to_string(index=False))\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Find best model based on validation RMSE\n",
    "best_idx = results_df['Val RMSE'].idxmin()\n",
    "best_model_name = results_df.loc[best_idx, 'Model']\n",
    "best_model = results_df.loc[best_idx, 'model_object']\n",
    "\n",
    "print(f\"\\nðŸ† Best Model: {best_model_name}\")\n",
    "print(f\"   Validation RMSE: {results_df.loc[best_idx, 'Val RMSE']:.6f}\")\n",
    "print(f\"   Validation RÂ²: {results_df.loc[best_idx, 'Val RÂ²']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# RMSE comparison\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "axes[0, 0].bar(x - width/2, results_df['Train RMSE'], width, label='Train', alpha=0.8)\n",
    "axes[0, 0].bar(x + width/2, results_df['Val RMSE'], width, label='Validation', alpha=0.8)\n",
    "axes[0, 0].set_xlabel('Model')\n",
    "axes[0, 0].set_ylabel('RMSE')\n",
    "axes[0, 0].set_title('Root Mean Squared Error Comparison')\n",
    "axes[0, 0].set_xticks(x)\n",
    "axes[0, 0].set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# RÂ² comparison\n",
    "axes[0, 1].bar(x - width/2, results_df['Train RÂ²'], width, label='Train', alpha=0.8)\n",
    "axes[0, 1].bar(x + width/2, results_df['Val RÂ²'], width, label='Validation', alpha=0.8)\n",
    "axes[0, 1].set_xlabel('Model')\n",
    "axes[0, 1].set_ylabel('RÂ² Score')\n",
    "axes[0, 1].set_title('RÂ² Score Comparison')\n",
    "axes[0, 1].set_xticks(x)\n",
    "axes[0, 1].set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE comparison\n",
    "axes[1, 0].bar(x - width/2, results_df['Train MAE'], width, label='Train', alpha=0.8)\n",
    "axes[1, 0].bar(x + width/2, results_df['Val MAE'], width, label='Validation', alpha=0.8)\n",
    "axes[1, 0].set_xlabel('Model')\n",
    "axes[1, 0].set_ylabel('MAE')\n",
    "axes[1, 0].set_title('Mean Absolute Error Comparison')\n",
    "axes[1, 0].set_xticks(x)\n",
    "axes[1, 0].set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Overfitting analysis (Train RMSE vs Val RMSE)\n",
    "axes[1, 1].scatter(results_df['Train RMSE'], results_df['Val RMSE'], s=100, alpha=0.6)\n",
    "for idx, row in results_df.iterrows():\n",
    "    axes[1, 1].annotate(row['Model'], (row['Train RMSE'], row['Val RMSE']), \n",
    "                        fontsize=8, ha='right')\n",
    "# Add diagonal line\n",
    "max_val = max(results_df['Train RMSE'].max(), results_df['Val RMSE'].max())\n",
    "axes[1, 1].plot([0, max_val], [0, max_val], 'r--', alpha=0.5, label='Perfect fit')\n",
    "axes[1, 1].set_xlabel('Train RMSE')\n",
    "axes[1, 1].set_ylabel('Validation RMSE')\n",
    "axes[1, 1].set_title('Overfitting Analysis')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from best model\n",
    "y_train_pred = best_model.predict(X_train_scaled)\n",
    "y_val_pred = best_model.predict(X_val_scaled)\n",
    "\n",
    "# Prediction vs Actual plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Training set\n",
    "axes[0].scatter(y_train, y_train_pred, alpha=0.3, s=10)\n",
    "axes[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Returns')\n",
    "axes[0].set_ylabel('Predicted Returns')\n",
    "axes[0].set_title(f'{best_model_name} - Training Set')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Validation set\n",
    "axes[1].scatter(y_val, y_val_pred, alpha=0.3, s=10, color='orange')\n",
    "axes[1].plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
    "axes[1].set_xlabel('Actual Returns')\n",
    "axes[1].set_ylabel('Predicted Returns')\n",
    "axes[1].set_title(f'{best_model_name} - Validation Set')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis\n",
    "train_residuals = y_train - y_train_pred\n",
    "val_residuals = y_val - y_val_pred\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Residual distribution - Training\n",
    "axes[0, 0].hist(train_residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Residuals')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Training Set - Residual Distribution')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual distribution - Validation\n",
    "axes[0, 1].hist(val_residuals, bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[0, 1].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Residuals')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Validation Set - Residual Distribution')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals vs Predicted - Training\n",
    "axes[1, 0].scatter(y_train_pred, train_residuals, alpha=0.3, s=10)\n",
    "axes[1, 0].axhline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Predicted Returns')\n",
    "axes[1, 0].set_ylabel('Residuals')\n",
    "axes[1, 0].set_title('Training Set - Residual Plot')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals vs Predicted - Validation\n",
    "axes[1, 1].scatter(y_val_pred, val_residuals, alpha=0.3, s=10, color='orange')\n",
    "axes[1, 1].axhline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Predicted Returns')\n",
    "axes[1, 1].set_ylabel('Residuals')\n",
    "axes[1, 1].set_title('Validation Set - Residual Plot')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Residual Statistics:\")\n",
    "print(f\"\\nTraining:\")\n",
    "print(f\"  Mean: {train_residuals.mean():.6f}\")\n",
    "print(f\"  Std: {train_residuals.std():.6f}\")\n",
    "print(f\"\\nValidation:\")\n",
    "print(f\"  Mean: {val_residuals.mean():.6f}\")\n",
    "print(f\"  Std: {val_residuals.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance (coefficients)\n",
    "if hasattr(best_model, 'coef_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': feature_cols,\n",
    "        'Coefficient': best_model.coef_,\n",
    "        'Abs_Coefficient': np.abs(best_model.coef_)\n",
    "    }).sort_values('Abs_Coefficient', ascending=False)\n",
    "    \n",
    "    print(\"Top 20 Most Important Features:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(feature_importance.head(20).to_string(index=False))\n",
    "    \n",
    "    # Plot top features\n",
    "    top_features = feature_importance.head(20)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    colors = ['green' if x > 0 else 'red' for x in top_features['Coefficient']]\n",
    "    plt.barh(range(len(top_features)), top_features['Coefficient'], color=colors, alpha=0.7)\n",
    "    plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "    plt.xlabel('Coefficient Value')\n",
    "    plt.title(f'Top 20 Feature Coefficients - {best_model_name}')\n",
    "    plt.axvline(0, color='black', linestyle='--', linewidth=1)\n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Count non-zero coefficients (for regularized models)\n",
    "    non_zero = (feature_importance['Abs_Coefficient'] > 1e-10).sum()\n",
    "    print(f\"\\nNon-zero coefficients: {non_zero} / {len(feature_cols)}\")\n",
    "else:\n",
    "    print(\"This model does not have coefficient information.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "y_test_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Set Performance - {best_model_name}:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  RMSE: {test_rmse:.6f}\")\n",
    "print(f\"  MAE: {test_mae:.6f}\")\n",
    "print(f\"  RÂ² Score: {test_r2:.6f}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Plot predictions vs actual\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5, s=20)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Perfect prediction')\n",
    "plt.xlabel('Actual Returns')\n",
    "plt.ylabel('Predicted Returns')\n",
    "plt.title(f'Test Set: Predicted vs Actual Returns\\n{best_model_name} (RMSE: {test_rmse:.6f}, RÂ²: {test_r2:.6f})')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "model_path = MODEL_DIR / 'best_linear_model.pkl'\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"âœ“ Best model saved to {model_path}\")\n",
    "\n",
    "# Save feature names\n",
    "feature_names_path = MODEL_DIR / 'feature_names.txt'\n",
    "with open(feature_names_path, 'w') as f:\n",
    "    for col in feature_cols:\n",
    "        f.write(f\"{col}\\n\")\n",
    "print(f\"âœ“ Feature names saved to {feature_names_path}\")\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'model_name': best_model_name,\n",
    "    'target': TARGET,\n",
    "    'n_features': len(feature_cols),\n",
    "    'train_size': len(X_train),\n",
    "    'val_size': len(X_val),\n",
    "    'test_size': len(X_test),\n",
    "    'val_rmse': results_df.loc[best_idx, 'Val RMSE'],\n",
    "    'val_r2': results_df.loc[best_idx, 'Val RÂ²'],\n",
    "    'test_rmse': test_rmse,\n",
    "    'test_r2': test_r2\n",
    "}\n",
    "\n",
    "metadata_path = MODEL_DIR / 'model_metadata.txt'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    for key, value in metadata.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "print(f\"âœ“ Model metadata saved to {metadata_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Model Training Complete!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Validation RMSE: {results_df.loc[best_idx, 'Val RMSE']:.6f}\")\n",
    "print(f\"Test RMSE: {test_rmse:.6f}\")\n",
    "print(f\"\\nModel saved to: {model_path}\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
