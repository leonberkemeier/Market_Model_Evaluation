{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model Training - Finance Sector\n",
    "**Purpose**: Train and optimize a Linear Regression model for Finance sector\n",
    "\n",
    "**Expected Performance**: Sharpe ~1.5 (Finance is mean-reverting, ideal for Linear models)\n",
    "\n",
    "**Date**: 2026-02-22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/archy/Desktop/Server/FinancialData/model_regime_comparison\n",
      "Python path updated\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up paths\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python path updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "Load Finance sector tickers for training period (2019-2024 H1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finance sector: 10 tickers\n",
      "Training: 2019-01-01 to 2024-06-30\n",
      "Hold-out: 2024-07-01 to 2024-12-31\n"
     ]
    }
   ],
   "source": [
    "# Finance sector tickers\n",
    "finance_tickers = ['JPM', 'BAC', 'GS', 'MS', 'WFC', 'C', 'BLK', 'AXP', 'USB', 'PNC']\n",
    "\n",
    "# Training period\n",
    "train_start = '2019-01-01'\n",
    "train_end = '2024-06-30'\n",
    "\n",
    "# Hold-out test period\n",
    "test_start = '2024-07-01'\n",
    "test_end = '2024-12-31'\n",
    "\n",
    "print(f\"Finance sector: {len(finance_tickers)} tickers\")\n",
    "print(f\"Training: {train_start} to {train_end}\")\n",
    "print(f\"Hold-out: {test_start} to {test_end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 1382 rows\n",
      "Test data: 128 rows\n",
      "\n",
      "Training tickers: 1\n",
      "Test tickers: 1\n"
     ]
    }
   ],
   "source": [
    "# Load data from database\n",
    "db_path = project_root / 'data' / 'financial_data.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Build query\n",
    "placeholders = ','.join(['?'] * len(finance_tickers))\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    d.date,\n",
    "    c.ticker,\n",
    "    s.open_price as open,\n",
    "    s.high_price as high,\n",
    "    s.low_price as low,\n",
    "    s.close_price as close,\n",
    "    s.adjusted_close,\n",
    "    s.volume\n",
    "FROM fact_stock_price s\n",
    "JOIN dim_date d ON s.date_id = d.date_id\n",
    "JOIN dim_company c ON s.company_id = c.company_id\n",
    "WHERE \n",
    "    c.ticker IN ({placeholders})\n",
    "    AND d.date BETWEEN ? AND ?\n",
    "ORDER BY d.date, c.ticker\n",
    "\"\"\"\n",
    "\n",
    "# Load training data\n",
    "train_df = pd.read_sql_query(\n",
    "    query, \n",
    "    conn, \n",
    "    params=tuple(finance_tickers) + (train_start, train_end)\n",
    ")\n",
    "train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_sql_query(\n",
    "    query, \n",
    "    conn, \n",
    "    params=tuple(finance_tickers) + (test_start, test_end)\n",
    ")\n",
    "test_df['date'] = pd.to_datetime(test_df['date'])\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(f\"Training data: {len(train_df)} rows\")\n",
    "print(f\"Test data: {len(test_df)} rows\")\n",
    "print(f\"\\nTraining tickers: {train_df['ticker'].nunique()}\")\n",
    "print(f\"Test tickers: {test_df['ticker'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "Create simple technical indicators for Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating features for training data...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Apply feature engineering\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCreating features for training data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m train_features = \u001b[43mcreate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCreating features for test data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     72\u001b[39m test_features = create_features(test_df)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mcreate_features\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     43\u001b[39m     rsi = \u001b[32m100\u001b[39m - (\u001b[32m100\u001b[39m / (\u001b[32m1\u001b[39m + rs))\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m rsi\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m features_df[\u001b[33m'\u001b[39m\u001b[33mrsi_14\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mfeatures_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mticker\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43madjusted_close\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalculate_rsi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m14\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Volume indicators\u001b[39;00m\n\u001b[32m     51\u001b[39m features_df[\u001b[33m'\u001b[39m\u001b[33mvolume_ma_20\u001b[39m\u001b[33m'\u001b[39m] = features_df.groupby(\u001b[33m'\u001b[39m\u001b[33mticker\u001b[39m\u001b[33m'\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mvolume\u001b[39m\u001b[33m'\u001b[39m].transform(\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m x: x.rolling(window=\u001b[32m20\u001b[39m).mean()\n\u001b[32m     53\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Server/FinancialData/model_regime_comparison/venv/lib/python3.14/site-packages/pandas/core/groupby/generic.py:786\u001b[39m, in \u001b[36mSeriesGroupBy.transform\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    651\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, *args, engine=\u001b[38;5;28;01mNone\u001b[39;00m, engine_kwargs=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    652\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    653\u001b[39m \u001b[33;03m    Call function producing a same-indexed Series on each group.\u001b[39;00m\n\u001b[32m    654\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    784\u001b[39m \u001b[33;03m    Name: Max Speed, dtype: int64\u001b[39;00m\n\u001b[32m    785\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Server/FinancialData/model_regime_comparison/venv/lib/python3.14/site-packages/pandas/core/groupby/groupby.py:1823\u001b[39m, in \u001b[36mGroupBy._transform\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m   1819\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m   1820\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, *args, engine=\u001b[38;5;28;01mNone\u001b[39;00m, engine_kwargs=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m   1821\u001b[39m     \u001b[38;5;66;03m# optimized transforms\u001b[39;00m\n\u001b[32m   1822\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1823\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_transform_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1825\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m func \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m base.transform_kernel_allowlist:\n\u001b[32m   1826\u001b[39m         msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is not a valid function name for transform(name)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Server/FinancialData/model_regime_comparison/venv/lib/python3.14/site-packages/pandas/core/groupby/generic.py:822\u001b[39m, in \u001b[36mSeriesGroupBy._transform_general\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    817\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._grouper.get_iterator(\n\u001b[32m    818\u001b[39m     \u001b[38;5;28mself\u001b[39m._obj_with_exclusions,\n\u001b[32m    819\u001b[39m ):\n\u001b[32m    820\u001b[39m     \u001b[38;5;66;03m# this setattr is needed for test_transform_lambda_with_datetimetz\u001b[39;00m\n\u001b[32m    821\u001b[39m     \u001b[38;5;28mobject\u001b[39m.\u001b[34m__setattr__\u001b[39m(group, \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m, name)\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m     res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    824\u001b[39m     results.append(klass(res, index=group.index))\n\u001b[32m    826\u001b[39m \u001b[38;5;66;03m# check for empty \"results\" to avoid concat ValueError\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mcreate_features.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     43\u001b[39m     rsi = \u001b[32m100\u001b[39m - (\u001b[32m100\u001b[39m / (\u001b[32m1\u001b[39m + rs))\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m rsi\n\u001b[32m     46\u001b[39m features_df[\u001b[33m'\u001b[39m\u001b[33mrsi_14\u001b[39m\u001b[33m'\u001b[39m] = features_df.groupby(\u001b[33m'\u001b[39m\u001b[33mticker\u001b[39m\u001b[33m'\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33madjusted_close\u001b[39m\u001b[33m'\u001b[39m].transform(\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mcalculate_rsi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m14\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m )\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Volume indicators\u001b[39;00m\n\u001b[32m     51\u001b[39m features_df[\u001b[33m'\u001b[39m\u001b[33mvolume_ma_20\u001b[39m\u001b[33m'\u001b[39m] = features_df.groupby(\u001b[33m'\u001b[39m\u001b[33mticker\u001b[39m\u001b[33m'\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mvolume\u001b[39m\u001b[33m'\u001b[39m].transform(\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m x: x.rolling(window=\u001b[32m20\u001b[39m).mean()\n\u001b[32m     53\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mcreate_features.<locals>.calculate_rsi\u001b[39m\u001b[34m(prices, period)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalculate_rsi\u001b[39m(prices, period=\u001b[32m14\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     delta = \u001b[43mprices\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     gain = (delta.where(delta > \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m)).rolling(window=period).mean()\n\u001b[32m     41\u001b[39m     loss = (-delta.where(delta < \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m)).rolling(window=period).mean()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Server/FinancialData/model_regime_comparison/venv/lib/python3.14/site-packages/pandas/core/series.py:2916\u001b[39m, in \u001b[36mSeries.diff\u001b[39m\u001b[34m(self, periods)\u001b[39m\n\u001b[32m   2914\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_float(periods) \u001b[38;5;129;01mand\u001b[39;00m periods.is_integer()):\n\u001b[32m   2915\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mperiods must be an integer\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2916\u001b[39m result = \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdiff\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiods\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2917\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._constructor(\n\u001b[32m   2918\u001b[39m     result, index=\u001b[38;5;28mself\u001b[39m.index.view(), copy=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2919\u001b[39m ).__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mdiff\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Server/FinancialData/model_regime_comparison/venv/lib/python3.14/site-packages/pandas/core/algorithms.py:1416\u001b[39m, in \u001b[36mdiff\u001b[39m\u001b[34m(arr, n, axis)\u001b[39m\n\u001b[32m   1413\u001b[39m     _lag_indexer[axis] = \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, -n) \u001b[38;5;28;01mif\u001b[39;00m n > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(-n, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1414\u001b[39m     lag_indexer = \u001b[38;5;28mtuple\u001b[39m(_lag_indexer)\n\u001b[32m-> \u001b[39m\u001b[32m1416\u001b[39m     out_arr[res_indexer] = \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mres_indexer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlag_indexer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1418\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_timedelta:\n\u001b[32m   1419\u001b[39m     out_arr = out_arr.view(\u001b[33m\"\u001b[39m\u001b[33mtimedelta64[ns]\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for -: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Create technical features for Linear model.\n",
    "    \n",
    "    Features:\n",
    "    - Returns (1, 5, 20 days)\n",
    "    - Moving averages (5, 20, 50 days)\n",
    "    - Volatility (rolling std)\n",
    "    - RSI\n",
    "    - Volume indicators\n",
    "    \"\"\"\n",
    "    features_df = df.copy()\n",
    "    \n",
    "    # Calculate returns\n",
    "    features_df['returns'] = features_df.groupby('ticker')['adjusted_close'].pct_change()\n",
    "    \n",
    "    # Lagged returns (features)\n",
    "    for lag in [1, 5, 10, 20]:\n",
    "        features_df[f'returns_lag_{lag}'] = features_df.groupby('ticker')['returns'].shift(lag)\n",
    "    \n",
    "    # Moving averages\n",
    "    for window in [5, 10, 20, 50]:\n",
    "        features_df[f'ma_{window}'] = features_df.groupby('ticker')['adjusted_close'].transform(\n",
    "            lambda x: x.rolling(window=window).mean()\n",
    "        )\n",
    "        # MA crossover (price vs MA)\n",
    "        features_df[f'price_vs_ma_{window}'] = (\n",
    "            features_df['adjusted_close'] / features_df[f'ma_{window}'] - 1\n",
    "        )\n",
    "    \n",
    "    # Volatility (rolling std of returns)\n",
    "    for window in [5, 10, 20]:\n",
    "        features_df[f'volatility_{window}'] = features_df.groupby('ticker')['returns'].transform(\n",
    "            lambda x: x.rolling(window=window).std()\n",
    "        )\n",
    "    \n",
    "    # RSI (Relative Strength Index)\n",
    "    def calculate_rsi(prices, period=14):\n",
    "        delta = prices.diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "        rs = gain / loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        return rsi\n",
    "    \n",
    "    features_df['rsi_14'] = features_df.groupby('ticker')['adjusted_close'].transform(\n",
    "        lambda x: calculate_rsi(x, 14)\n",
    "    )\n",
    "    \n",
    "    # Volume indicators\n",
    "    features_df['volume_ma_20'] = features_df.groupby('ticker')['volume'].transform(\n",
    "        lambda x: x.rolling(window=20).mean()\n",
    "    )\n",
    "    features_df['volume_ratio'] = features_df['volume'] / features_df['volume_ma_20']\n",
    "    \n",
    "    # Price momentum\n",
    "    for window in [5, 10, 20]:\n",
    "        features_df[f'momentum_{window}'] = features_df.groupby('ticker')['adjusted_close'].transform(\n",
    "            lambda x: x.pct_change(periods=window)\n",
    "        )\n",
    "    \n",
    "    # High-Low spread\n",
    "    features_df['hl_spread'] = (features_df['high'] - features_df['low']) / features_df['close']\n",
    "    \n",
    "    return features_df\n",
    "\n",
    "# Apply feature engineering\n",
    "print(\"Creating features for training data...\")\n",
    "train_features = create_features(train_df)\n",
    "\n",
    "print(\"Creating features for test data...\")\n",
    "test_features = create_features(test_df)\n",
    "\n",
    "print(f\"\\nTotal features created: {len(train_features.columns)}\")\n",
    "print(f\"\\nSample features:\")\n",
    "print(train_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for Training\n",
    "\n",
    "Select feature columns and target (next day returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select feature columns (exclude date, ticker, price columns)\n",
    "exclude_cols = ['date', 'ticker', 'open', 'high', 'low', 'close', 'adjusted_close', 'volume', 'returns']\n",
    "\n",
    "feature_cols = [col for col in train_features.columns if col not in exclude_cols]\n",
    "\n",
    "print(f\"Feature columns ({len(feature_cols)}):\")\n",
    "for col in feature_cols:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "# Target: next day returns\n",
    "train_features['target'] = train_features.groupby('ticker')['returns'].shift(-1)\n",
    "test_features['target'] = test_features.groupby('ticker')['returns'].shift(-1)\n",
    "\n",
    "# Drop rows with NaN (from rolling windows and target shift)\n",
    "train_clean = train_features.dropna()\n",
    "test_clean = test_features.dropna()\n",
    "\n",
    "print(f\"\\nClean training data: {len(train_clean)} rows\")\n",
    "print(f\"Clean test data: {len(test_clean)} rows\")\n",
    "\n",
    "# Extract X and y\n",
    "X_train = train_clean[feature_cols]\n",
    "y_train = train_clean['target']\n",
    "\n",
    "X_test = test_clean[feature_cols]\n",
    "y_test = test_clean['target']\n",
    "\n",
    "print(f\"\\nX_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Tuning with Time Series Cross-Validation\n",
    "\n",
    "Find best alpha (L2 regularization strength) using walk-forward validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha values to test\n",
    "alpha_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "# Time series cross-validation (5 splits)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Store results\n",
    "cv_results = []\n",
    "\n",
    "print(\"Running hyperparameter tuning...\\n\")\n",
    "\n",
    "for alpha in alpha_range:\n",
    "    fold_scores = []\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(tscv.split(X_train)):\n",
    "        # Split data\n",
    "        X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_fold_train_scaled = scaler.fit_transform(X_fold_train)\n",
    "        X_fold_val_scaled = scaler.transform(X_fold_val)\n",
    "        \n",
    "        # Train model\n",
    "        model = Ridge(alpha=alpha, random_state=42)\n",
    "        model.fit(X_fold_train_scaled, y_fold_train)\n",
    "        \n",
    "        # Validate\n",
    "        val_pred = model.predict(X_fold_val_scaled)\n",
    "        r2 = r2_score(y_fold_val, val_pred)\n",
    "        fold_scores.append(r2)\n",
    "    \n",
    "    mean_r2 = np.mean(fold_scores)\n",
    "    std_r2 = np.std(fold_scores)\n",
    "    \n",
    "    cv_results.append({\n",
    "        'alpha': alpha,\n",
    "        'mean_r2': mean_r2,\n",
    "        'std_r2': std_r2\n",
    "    })\n",
    "    \n",
    "    print(f\"Alpha={alpha:7.3f}: R2={mean_r2:.4f} (+/- {std_r2:.4f})\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "\n",
    "# Find best alpha\n",
    "best_alpha = cv_df.loc[cv_df['mean_r2'].idxmax(), 'alpha']\n",
    "best_r2 = cv_df.loc[cv_df['mean_r2'].idxmax(), 'mean_r2']\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "print(f\"Best CV R2: {best_r2:.4f}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(cv_df['alpha'], cv_df['mean_r2'], yerr=cv_df['std_r2'], \n",
    "             marker='o', capsize=5, capthick=2)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Alpha (L2 Regularization)', fontsize=12)\n",
    "plt.ylabel('Mean R² Score', fontsize=12)\n",
    "plt.title('Cross-Validation Results: Alpha Tuning', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axvline(x=best_alpha, color='red', linestyle='--', label=f'Best alpha={best_alpha}')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Final Model\n",
    "\n",
    "Train with best alpha on full training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train final model\n",
    "print(f\"Training final model with alpha={best_alpha}...\")\n",
    "final_model = Ridge(alpha=best_alpha, random_state=42)\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Training predictions\n",
    "y_train_pred = final_model.predict(X_train_scaled)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "print(f\"\\nTraining Performance:\")\n",
    "print(f\"  R² Score: {train_r2:.4f}\")\n",
    "print(f\"  MSE: {train_mse:.6f}\")\n",
    "print(f\"  RMSE: {np.sqrt(train_mse):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance\n",
    "\n",
    "Analyze which features are most important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature coefficients\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'coefficient': final_model.coef_\n",
    "})\n",
    "feature_importance['abs_coefficient'] = np.abs(feature_importance['coefficient'])\n",
    "feature_importance = feature_importance.sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "print(\"Top 15 Most Important Features:\")\n",
    "print(feature_importance.head(15))\n",
    "\n",
    "# Visualize top features\n",
    "top_n = 15\n",
    "top_features = feature_importance.head(top_n)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(range(top_n), top_features['coefficient'].values)\n",
    "plt.yticks(range(top_n), top_features['feature'].values)\n",
    "plt.xlabel('Coefficient Value', fontsize=12)\n",
    "plt.title(f'Top {top_n} Feature Coefficients', fontsize=14)\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate on Hold-Out Test Set\n",
    "\n",
    "Test on completely unseen data (2024 H2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions\n",
    "y_test_pred = final_model.predict(X_test_scaled)\n",
    "\n",
    "# Test performance\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Hold-Out Test Performance:\")\n",
    "print(f\"  R² Score: {test_r2:.4f}\")\n",
    "print(f\"  MSE: {test_mse:.6f}\")\n",
    "print(f\"  RMSE: {np.sqrt(test_mse):.6f}\")\n",
    "\n",
    "# Safety check: Retention rate\n",
    "retention_rate = test_r2 / train_r2 if train_r2 > 0 else 0\n",
    "print(f\"\\nRetention Rate: {retention_rate:.2%}\")\n",
    "print(f\"Safety Check: {'✓ PASS' if retention_rate >= 0.80 else '✗ FAIL'} (≥80% required)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actuals\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Training set\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_train, y_train_pred, alpha=0.3, s=10)\n",
    "plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], \n",
    "         'r--', lw=2, label='Perfect prediction')\n",
    "plt.xlabel('Actual Returns', fontsize=11)\n",
    "plt.ylabel('Predicted Returns', fontsize=11)\n",
    "plt.title(f'Training Set (R²={train_r2:.3f})', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Test set\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.3, s=10, color='orange')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "         'r--', lw=2, label='Perfect prediction')\n",
    "plt.xlabel('Actual Returns', fontsize=11)\n",
    "plt.ylabel('Predicted Returns', fontsize=11)\n",
    "plt.title(f'Test Set (R²={test_r2:.3f})', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Trading Strategy Simulation\n",
    "\n",
    "Simulate trades based on predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to test data\n",
    "test_results = test_clean.copy()\n",
    "test_results['predicted_return'] = y_test_pred\n",
    "test_results['actual_return'] = y_test.values\n",
    "\n",
    "# Simple strategy: Go long if predicted return > threshold\n",
    "threshold = 0.0  # Can optimize this\n",
    "test_results['signal'] = (test_results['predicted_return'] > threshold).astype(int)\n",
    "\n",
    "# Calculate strategy returns\n",
    "test_results['strategy_return'] = test_results['signal'] * test_results['actual_return']\n",
    "\n",
    "# Cumulative returns\n",
    "test_results['cumulative_return'] = (1 + test_results['actual_return']).cumprod() - 1\n",
    "test_results['cumulative_strategy'] = (1 + test_results['strategy_return']).cumprod() - 1\n",
    "\n",
    "print(f\"Strategy Performance (Test Set):\")\n",
    "print(f\"  Total trades: {test_results['signal'].sum()}\")\n",
    "print(f\"  Win rate: {(test_results[test_results['signal']==1]['actual_return'] > 0).mean():.2%}\")\n",
    "print(f\"  Buy-and-hold return: {test_results['cumulative_return'].iloc[-1]:.2%}\")\n",
    "print(f\"  Strategy return: {test_results['cumulative_strategy'].iloc[-1]:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Sharpe ratio\n",
    "strategy_returns = test_results['strategy_return']\n",
    "sharpe_ratio = (strategy_returns.mean() / strategy_returns.std()) * np.sqrt(252)  # Annualized\n",
    "\n",
    "print(f\"\\nSharpe Ratio (Annualized): {sharpe_ratio:.3f}\")\n",
    "print(f\"Target Sharpe for Finance: ~1.5\")\n",
    "print(f\"Performance: {'✓ Good' if sharpe_ratio >= 1.0 else '✗ Needs improvement'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative returns\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.plot(test_results['date'], test_results['cumulative_return'], \n",
    "         label='Buy and Hold', alpha=0.7)\n",
    "plt.plot(test_results['date'], test_results['cumulative_strategy'], \n",
    "         label='Strategy (Model-based)', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Cumulative Return', fontsize=12)\n",
    "plt.title('Strategy Performance vs Buy-and-Hold (Test Period)', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Model\n",
    "\n",
    "Save trained model and scaler for production use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Create models directory\n",
    "models_dir = project_root / 'models'\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = models_dir / 'linear_finance_model.pkl'\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'model': final_model,\n",
    "        'scaler': scaler,\n",
    "        'feature_cols': feature_cols,\n",
    "        'best_alpha': best_alpha,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'sharpe_ratio': sharpe_ratio\n",
    "    }, f)\n",
    "\n",
    "print(f\"✓ Model saved to: {model_path}\")\n",
    "print(f\"\\nModel info:\")\n",
    "print(f\"  Features: {len(feature_cols)}\")\n",
    "print(f\"  Alpha: {best_alpha}\")\n",
    "print(f\"  Train R²: {train_r2:.4f}\")\n",
    "print(f\"  Test R²: {test_r2:.4f}\")\n",
    "print(f\"  Sharpe: {sharpe_ratio:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"LINEAR MODEL TRAINING SUMMARY - FINANCE SECTOR\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nData:\")\n",
    "print(f\"  Training period: {train_start} to {train_end}\")\n",
    "print(f\"  Test period: {test_start} to {test_end}\")\n",
    "print(f\"  Tickers: {len(finance_tickers)} ({', '.join(finance_tickers[:5])}, ...)\")\n",
    "print(f\"  Features: {len(feature_cols)}\")\n",
    "\n",
    "print(f\"\\nModel:\")\n",
    "print(f\"  Type: Ridge Regression (L2 regularization)\")\n",
    "print(f\"  Best alpha: {best_alpha}\")\n",
    "\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  Train R²: {train_r2:.4f}\")\n",
    "print(f\"  Test R²: {test_r2:.4f}\")\n",
    "print(f\"  Retention: {retention_rate:.2%} {'✓' if retention_rate >= 0.80 else '✗'}\")\n",
    "print(f\"  Sharpe Ratio: {sharpe_ratio:.3f} (Target: ~1.5)\")\n",
    "\n",
    "print(f\"\\nNext Steps:\")\n",
    "print(f\"  1. Try different feature engineering approaches\")\n",
    "print(f\"  2. Optimize trading strategy threshold\")\n",
    "print(f\"  3. Test on other sectors (commodities)\")\n",
    "print(f\"  4. Compare with XGBoost model\")\n",
    "print(f\"  5. Integrate into Sentinel pipeline\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
