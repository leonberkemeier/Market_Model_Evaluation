{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model Training - Finance Sector\n",
    "**Purpose**: Train and optimize a Linear Regression model for Finance sector\n",
    "\n",
    "**Expected Performance**: Sharpe ~1.5 (Finance is mean-reverting, ideal for Linear models)\n",
    "\n",
    "**Date**: 2026-02-22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up paths\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python path updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "Load Finance sector tickers for training period (2019-2024 H1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finance sector tickers\n",
    "finance_tickers = ['JPM', 'BAC', 'GS', 'MS', 'WFC', 'C', 'BLK', 'AXP', 'USB', 'PNC']\n",
    "\n",
    "# Training period\n",
    "train_start = '2019-01-01'\n",
    "train_end = '2024-06-30'\n",
    "\n",
    "# Hold-out test period\n",
    "test_start = '2024-07-01'\n",
    "test_end = '2024-12-31'\n",
    "\n",
    "print(f\"Finance sector: {len(finance_tickers)} tickers\")\n",
    "print(f\"Training: {train_start} to {train_end}\")\n",
    "print(f\"Hold-out: {test_start} to {test_end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from database\n",
    "db_path = project_root / 'data' / 'financial_data.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Build query\n",
    "placeholders = ','.join(['?'] * len(finance_tickers))\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    d.date,\n",
    "    c.ticker,\n",
    "    s.open_price as open,\n",
    "    s.high_price as high,\n",
    "    s.low_price as low,\n",
    "    s.close_price as close,\n",
    "    s.adjusted_close,\n",
    "    s.volume\n",
    "FROM fact_stock_price s\n",
    "JOIN dim_date d ON s.date_id = d.date_id\n",
    "JOIN dim_company c ON s.company_id = c.company_id\n",
    "WHERE \n",
    "    c.ticker IN ({placeholders})\n",
    "    AND d.date BETWEEN ? AND ?\n",
    "ORDER BY d.date, c.ticker\n",
    "\"\"\"\n",
    "\n",
    "# Load training data\n",
    "train_df = pd.read_sql_query(\n",
    "    query, \n",
    "    conn, \n",
    "    params=tuple(finance_tickers) + (train_start, train_end)\n",
    ")\n",
    "train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_sql_query(\n",
    "    query, \n",
    "    conn, \n",
    "    params=tuple(finance_tickers) + (test_start, test_end)\n",
    ")\n",
    "test_df['date'] = pd.to_datetime(test_df['date'])\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(f\"Training data: {len(train_df)} rows\")\n",
    "print(f\"Test data: {len(test_df)} rows\")\n",
    "print(f\"\\nTraining tickers: {train_df['ticker'].nunique()}\")\n",
    "print(f\"Test tickers: {test_df['ticker'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "Create simple technical indicators for Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Create technical features for Linear model.\n",
    "    \n",
    "    Features:\n",
    "    - Returns (1, 5, 20 days)\n",
    "    - Moving averages (5, 20, 50 days)\n",
    "    - Volatility (rolling std)\n",
    "    - RSI\n",
    "    - Volume indicators\n",
    "    \"\"\"\n",
    "    features_df = df.copy()\n",
    "    \n",
    "    # Calculate returns\n",
    "    features_df['returns'] = features_df.groupby('ticker')['adjusted_close'].pct_change()\n",
    "    \n",
    "    # Lagged returns (features)\n",
    "    for lag in [1, 5, 10, 20]:\n",
    "        features_df[f'returns_lag_{lag}'] = features_df.groupby('ticker')['returns'].shift(lag)\n",
    "    \n",
    "    # Moving averages\n",
    "    for window in [5, 10, 20, 50]:\n",
    "        features_df[f'ma_{window}'] = features_df.groupby('ticker')['adjusted_close'].transform(\n",
    "            lambda x: x.rolling(window=window).mean()\n",
    "        )\n",
    "        # MA crossover (price vs MA)\n",
    "        features_df[f'price_vs_ma_{window}'] = (\n",
    "            features_df['adjusted_close'] / features_df[f'ma_{window}'] - 1\n",
    "        )\n",
    "    \n",
    "    # Volatility (rolling std of returns)\n",
    "    for window in [5, 10, 20]:\n",
    "        features_df[f'volatility_{window}'] = features_df.groupby('ticker')['returns'].transform(\n",
    "            lambda x: x.rolling(window=window).std()\n",
    "        )\n",
    "    \n",
    "    # RSI (Relative Strength Index)\n",
    "    def calculate_rsi(prices, period=14):\n",
    "        delta = prices.diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "        rs = gain / loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        return rsi\n",
    "    \n",
    "    features_df['rsi_14'] = features_df.groupby('ticker')['adjusted_close'].transform(\n",
    "        lambda x: calculate_rsi(x, 14)\n",
    "    )\n",
    "    \n",
    "    # Volume indicators\n",
    "    features_df['volume_ma_20'] = features_df.groupby('ticker')['volume'].transform(\n",
    "        lambda x: x.rolling(window=20).mean()\n",
    "    )\n",
    "    features_df['volume_ratio'] = features_df['volume'] / features_df['volume_ma_20']\n",
    "    \n",
    "    # Price momentum\n",
    "    for window in [5, 10, 20]:\n",
    "        features_df[f'momentum_{window}'] = features_df.groupby('ticker')['adjusted_close'].transform(\n",
    "            lambda x: x.pct_change(periods=window)\n",
    "        )\n",
    "    \n",
    "    # High-Low spread\n",
    "    features_df['hl_spread'] = (features_df['high'] - features_df['low']) / features_df['close']\n",
    "    \n",
    "    return features_df\n",
    "\n",
    "# Apply feature engineering\n",
    "print(\"Creating features for training data...\")\n",
    "train_features = create_features(train_df)\n",
    "\n",
    "print(\"Creating features for test data...\")\n",
    "test_features = create_features(test_df)\n",
    "\n",
    "print(f\"\\nTotal features created: {len(train_features.columns)}\")\n",
    "print(f\"\\nSample features:\")\n",
    "print(train_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for Training\n",
    "\n",
    "Select feature columns and target (next day returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select feature columns (exclude date, ticker, price columns)\n",
    "exclude_cols = ['date', 'ticker', 'open', 'high', 'low', 'close', 'adjusted_close', 'volume', 'returns']\n",
    "\n",
    "feature_cols = [col for col in train_features.columns if col not in exclude_cols]\n",
    "\n",
    "print(f\"Feature columns ({len(feature_cols)}):\")\n",
    "for col in feature_cols:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "# Target: next day returns\n",
    "train_features['target'] = train_features.groupby('ticker')['returns'].shift(-1)\n",
    "test_features['target'] = test_features.groupby('ticker')['returns'].shift(-1)\n",
    "\n",
    "# Drop rows with NaN (from rolling windows and target shift)\n",
    "train_clean = train_features.dropna()\n",
    "test_clean = test_features.dropna()\n",
    "\n",
    "print(f\"\\nClean training data: {len(train_clean)} rows\")\n",
    "print(f\"Clean test data: {len(test_clean)} rows\")\n",
    "\n",
    "# Extract X and y\n",
    "X_train = train_clean[feature_cols]\n",
    "y_train = train_clean['target']\n",
    "\n",
    "X_test = test_clean[feature_cols]\n",
    "y_test = test_clean['target']\n",
    "\n",
    "print(f\"\\nX_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Tuning with Time Series Cross-Validation\n",
    "\n",
    "Find best alpha (L2 regularization strength) using walk-forward validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha values to test\n",
    "alpha_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "# Time series cross-validation (5 splits)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Store results\n",
    "cv_results = []\n",
    "\n",
    "print(\"Running hyperparameter tuning...\\n\")\n",
    "\n",
    "for alpha in alpha_range:\n",
    "    fold_scores = []\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(tscv.split(X_train)):\n",
    "        # Split data\n",
    "        X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_fold_train_scaled = scaler.fit_transform(X_fold_train)\n",
    "        X_fold_val_scaled = scaler.transform(X_fold_val)\n",
    "        \n",
    "        # Train model\n",
    "        model = Ridge(alpha=alpha, random_state=42)\n",
    "        model.fit(X_fold_train_scaled, y_fold_train)\n",
    "        \n",
    "        # Validate\n",
    "        val_pred = model.predict(X_fold_val_scaled)\n",
    "        r2 = r2_score(y_fold_val, val_pred)\n",
    "        fold_scores.append(r2)\n",
    "    \n",
    "    mean_r2 = np.mean(fold_scores)\n",
    "    std_r2 = np.std(fold_scores)\n",
    "    \n",
    "    cv_results.append({\n",
    "        'alpha': alpha,\n",
    "        'mean_r2': mean_r2,\n",
    "        'std_r2': std_r2\n",
    "    })\n",
    "    \n",
    "    print(f\"Alpha={alpha:7.3f}: R2={mean_r2:.4f} (+/- {std_r2:.4f})\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "\n",
    "# Find best alpha\n",
    "best_alpha = cv_df.loc[cv_df['mean_r2'].idxmax(), 'alpha']\n",
    "best_r2 = cv_df.loc[cv_df['mean_r2'].idxmax(), 'mean_r2']\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "print(f\"Best CV R2: {best_r2:.4f}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(cv_df['alpha'], cv_df['mean_r2'], yerr=cv_df['std_r2'], \n",
    "             marker='o', capsize=5, capthick=2)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Alpha (L2 Regularization)', fontsize=12)\n",
    "plt.ylabel('Mean R² Score', fontsize=12)\n",
    "plt.title('Cross-Validation Results: Alpha Tuning', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axvline(x=best_alpha, color='red', linestyle='--', label=f'Best alpha={best_alpha}')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Final Model\n",
    "\n",
    "Train with best alpha on full training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train final model\n",
    "print(f\"Training final model with alpha={best_alpha}...\")\n",
    "final_model = Ridge(alpha=best_alpha, random_state=42)\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Training predictions\n",
    "y_train_pred = final_model.predict(X_train_scaled)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "print(f\"\\nTraining Performance:\")\n",
    "print(f\"  R² Score: {train_r2:.4f}\")\n",
    "print(f\"  MSE: {train_mse:.6f}\")\n",
    "print(f\"  RMSE: {np.sqrt(train_mse):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance\n",
    "\n",
    "Analyze which features are most important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature coefficients\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'coefficient': final_model.coef_\n",
    "})\n",
    "feature_importance['abs_coefficient'] = np.abs(feature_importance['coefficient'])\n",
    "feature_importance = feature_importance.sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "print(\"Top 15 Most Important Features:\")\n",
    "print(feature_importance.head(15))\n",
    "\n",
    "# Visualize top features\n",
    "top_n = 15\n",
    "top_features = feature_importance.head(top_n)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(range(top_n), top_features['coefficient'].values)\n",
    "plt.yticks(range(top_n), top_features['feature'].values)\n",
    "plt.xlabel('Coefficient Value', fontsize=12)\n",
    "plt.title(f'Top {top_n} Feature Coefficients', fontsize=14)\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate on Hold-Out Test Set\n",
    "\n",
    "Test on completely unseen data (2024 H2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions\n",
    "y_test_pred = final_model.predict(X_test_scaled)\n",
    "\n",
    "# Test performance\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Hold-Out Test Performance:\")\n",
    "print(f\"  R² Score: {test_r2:.4f}\")\n",
    "print(f\"  MSE: {test_mse:.6f}\")\n",
    "print(f\"  RMSE: {np.sqrt(test_mse):.6f}\")\n",
    "\n",
    "# Safety check: Retention rate\n",
    "retention_rate = test_r2 / train_r2 if train_r2 > 0 else 0\n",
    "print(f\"\\nRetention Rate: {retention_rate:.2%}\")\n",
    "print(f\"Safety Check: {'✓ PASS' if retention_rate >= 0.80 else '✗ FAIL'} (≥80% required)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actuals\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Training set\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_train, y_train_pred, alpha=0.3, s=10)\n",
    "plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], \n",
    "         'r--', lw=2, label='Perfect prediction')\n",
    "plt.xlabel('Actual Returns', fontsize=11)\n",
    "plt.ylabel('Predicted Returns', fontsize=11)\n",
    "plt.title(f'Training Set (R²={train_r2:.3f})', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Test set\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.3, s=10, color='orange')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "         'r--', lw=2, label='Perfect prediction')\n",
    "plt.xlabel('Actual Returns', fontsize=11)\n",
    "plt.ylabel('Predicted Returns', fontsize=11)\n",
    "plt.title(f'Test Set (R²={test_r2:.3f})', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Trading Strategy Simulation\n",
    "\n",
    "Simulate trades based on predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to test data\n",
    "test_results = test_clean.copy()\n",
    "test_results['predicted_return'] = y_test_pred\n",
    "test_results['actual_return'] = y_test.values\n",
    "\n",
    "# Simple strategy: Go long if predicted return > threshold\n",
    "threshold = 0.0  # Can optimize this\n",
    "test_results['signal'] = (test_results['predicted_return'] > threshold).astype(int)\n",
    "\n",
    "# Calculate strategy returns\n",
    "test_results['strategy_return'] = test_results['signal'] * test_results['actual_return']\n",
    "\n",
    "# Cumulative returns\n",
    "test_results['cumulative_return'] = (1 + test_results['actual_return']).cumprod() - 1\n",
    "test_results['cumulative_strategy'] = (1 + test_results['strategy_return']).cumprod() - 1\n",
    "\n",
    "print(f\"Strategy Performance (Test Set):\")\n",
    "print(f\"  Total trades: {test_results['signal'].sum()}\")\n",
    "print(f\"  Win rate: {(test_results[test_results['signal']==1]['actual_return'] > 0).mean():.2%}\")\n",
    "print(f\"  Buy-and-hold return: {test_results['cumulative_return'].iloc[-1]:.2%}\")\n",
    "print(f\"  Strategy return: {test_results['cumulative_strategy'].iloc[-1]:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Sharpe ratio\n",
    "strategy_returns = test_results['strategy_return']\n",
    "sharpe_ratio = (strategy_returns.mean() / strategy_returns.std()) * np.sqrt(252)  # Annualized\n",
    "\n",
    "print(f\"\\nSharpe Ratio (Annualized): {sharpe_ratio:.3f}\")\n",
    "print(f\"Target Sharpe for Finance: ~1.5\")\n",
    "print(f\"Performance: {'✓ Good' if sharpe_ratio >= 1.0 else '✗ Needs improvement'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative returns\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.plot(test_results['date'], test_results['cumulative_return'], \n",
    "         label='Buy and Hold', alpha=0.7)\n",
    "plt.plot(test_results['date'], test_results['cumulative_strategy'], \n",
    "         label='Strategy (Model-based)', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Cumulative Return', fontsize=12)\n",
    "plt.title('Strategy Performance vs Buy-and-Hold (Test Period)', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Model\n",
    "\n",
    "Save trained model and scaler for production use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Create models directory\n",
    "models_dir = project_root / 'models'\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = models_dir / 'linear_finance_model.pkl'\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'model': final_model,\n",
    "        'scaler': scaler,\n",
    "        'feature_cols': feature_cols,\n",
    "        'best_alpha': best_alpha,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'sharpe_ratio': sharpe_ratio\n",
    "    }, f)\n",
    "\n",
    "print(f\"✓ Model saved to: {model_path}\")\n",
    "print(f\"\\nModel info:\")\n",
    "print(f\"  Features: {len(feature_cols)}\")\n",
    "print(f\"  Alpha: {best_alpha}\")\n",
    "print(f\"  Train R²: {train_r2:.4f}\")\n",
    "print(f\"  Test R²: {test_r2:.4f}\")\n",
    "print(f\"  Sharpe: {sharpe_ratio:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"LINEAR MODEL TRAINING SUMMARY - FINANCE SECTOR\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nData:\")\n",
    "print(f\"  Training period: {train_start} to {train_end}\")\n",
    "print(f\"  Test period: {test_start} to {test_end}\")\n",
    "print(f\"  Tickers: {len(finance_tickers)} ({', '.join(finance_tickers[:5])}, ...)\")\n",
    "print(f\"  Features: {len(feature_cols)}\")\n",
    "\n",
    "print(f\"\\nModel:\")\n",
    "print(f\"  Type: Ridge Regression (L2 regularization)\")\n",
    "print(f\"  Best alpha: {best_alpha}\")\n",
    "\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  Train R²: {train_r2:.4f}\")\n",
    "print(f\"  Test R²: {test_r2:.4f}\")\n",
    "print(f\"  Retention: {retention_rate:.2%} {'✓' if retention_rate >= 0.80 else '✗'}\")\n",
    "print(f\"  Sharpe Ratio: {sharpe_ratio:.3f} (Target: ~1.5)\")\n",
    "\n",
    "print(f\"\\nNext Steps:\")\n",
    "print(f\"  1. Try different feature engineering approaches\")\n",
    "print(f\"  2. Optimize trading strategy threshold\")\n",
    "print(f\"  3. Test on other sectors (commodities)\")\n",
    "print(f\"  4. Compare with XGBoost model\")\n",
    "print(f\"  5. Integrate into Sentinel pipeline\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
